{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebabbbab-c235-4789-a004-14e69d06ec9d",
   "metadata": {},
   "source": [
    "# Data Analytics Spring 2023 &mdash; Exercises 1\n",
    "\n",
    "### Onni Roivas (last modified: Tue Jan 10 at 10:45)\n",
    "\n",
    "- Five problems\n",
    "- Minor variations between users\n",
    "- Theme: Python & Numpy (no Pandas allowed)\n",
    "- Hints will be given during the opening weekend\n",
    "- Deadline: about a week from the opening weekend (to be specified)\n",
    "- Make a copy of the original notebook (right click & duplicate) and add your answers (new cells) there\n",
    "- Please make both your code and your notebook readable\n",
    "- When you are done, run the handin code cell at the end of this notebook\n",
    "- The original notebook may change after publication, but the\n",
    "  changes should be minor (e.g. the deadline above)\n",
    "- Keep your originals up to date by running the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde89ee5-64f7-4289-8065-d36dfc25c58d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('/usr/bin/bash /home/varpha/data_analytics/bin/config.sh');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c82629f-43fd-4272-a4a2-97addd6614b6",
   "metadata": {},
   "source": [
    "## Problem 1. Documentation\n",
    "- read [this function documentation](https://numpy.org/doc/stable/reference/generated/numpy.concatenate.html) and explain the function to your anonymous peer reviewer.\n",
    "\n",
    "Please write a nice and clear explanation. Include some elementary examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4046d89d-9e52-4e7b-bf3b-be4eef54d6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenation refers to joining. This function is used to join two or more arrays of the same shape along a specified axis.\n",
    "# Parameters taken = numpy.concatenate((a1, a2, ...), axis)\n",
    "\n",
    "# example\n",
    "import numpy as np\n",
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "b = np.array([[7, 8, 9], [10, 11, 12]])\n",
    "np.concatenate((a, b), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afe4d8d-c0fc-43f7-b336-3fc95dd0dd76",
   "metadata": {},
   "source": [
    "## Problem 2. Map, Lambda, Groupby\n",
    "In this problem, only plain python may be used, no numpy.<br/>\n",
    "The following links may be helpful:\n",
    "- [sorting howto](https://docs.python.org/3/howto/sorting.html)\n",
    "- [lambda sorting](https://blogboard.io/blog/knowledge/python-sorted-lambda)\n",
    "- [itertools groupby](https://stackoverflow.com/questions/773/how-do-i-use-itertools-groupby).\n",
    "\n",
    "Using the code cell below, read a csv (real wind turbine data) into a list of dicts.<br/>\n",
    "Then do the following:\n",
    "- a) using map and lambda, convert the timestamps into the format <b>MM/dd/yyyy HH:mm:ss</b>, e.g. 11/04/2018 09:10:43\n",
    "- b) using sorted and lambda, sort the rows according to increasing rotorspeed\n",
    "- c) add a column called <b><i>WindSpeed_Group</i></b> that contains a windspeed group A, B or C, where A = less than 5mps, B = 5-10mps, C = more than 10mps. Use [itertools.groupby](https://docs.python.org/3/library/itertools.html#itertools.groupby).\n",
    "\n",
    "In your handin, include the code that does a) - c) above. No need to save the modified data. Here is the code for reading the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb4d7b0-f176-4df6-abed-f680ff3ee56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getuser\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from itertools import groupby\n",
    "\n",
    "user = getuser().upper()\n",
    "csv_location = f'/home/varpha/data_analytics/private/{user}' + \\\n",
    "                f'/exrc_01/data/prob2_{user}.csv'\n",
    "with open(csv_location) as handle:\n",
    "    mydata = list(csv.DictReader(handle))\n",
    "    mydata = list(map(lambda x: {'TimeStamp': datetime.strptime(x['TimeStamp'], \n",
    "    '%Y-%m-%d %H:%M:%S.%f').strftime('%m/%d/%Y %H:%M:%S'),\n",
    "    'WindSpeed_mps': x['WindSpeed_mps'],\n",
    "    'RotorSpeed_rpm': x['RotorSpeed_rpm']}, mydata))\n",
    "\n",
    "    mydata = [row for row in mydata if row['RotorSpeed_rpm'] != '']\n",
    "    mydata = sorted(mydata, key=lambda x: float(x['RotorSpeed_rpm']))\n",
    "\n",
    "    def windspeed_group_fn(row):\n",
    "        if float(row['WindSpeed_mps']) < 5:\n",
    "            return 'A'\n",
    "        elif 5 <= float(row['WindSpeed_mps']) <= 10:\n",
    "            return 'B'\n",
    "        else:\n",
    "            return 'C'\n",
    "    mydata = [{**row, 'WindSpeed_Group': windspeed_group_fn(row)} for row in mydata]\n",
    "    mydata = sorted(mydata, key=lambda x: x['WindSpeed_Group'])\n",
    "    for key, group in groupby(mydata, key=lambda x: x['WindSpeed_Group']):\n",
    "        print(key + ':\\n')\n",
    "        for row in group:\n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fc3925-ea46-4069-a059-1adc344dd929",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Problem 3. Vectorization\n",
    "\n",
    "- Some [general info](https://www.askpython.com/python-modules/numpy/vectorization-numpy)\n",
    "- The code in <b>data_analytics/lib/integrator.py</b> contains rudimentary code,<br/>\n",
    "  written in plain python, that numerically integrates a (math) function<br/>\n",
    "  $f\\colon \\mathbb{R} \\to \\mathbb{R}$ over an interval $[a,b]$.\n",
    "- Rewrite the code using numpy and vectorization.\n",
    "- Introduce timings to measure the gain of vectorization.\n",
    "- Use the (math) function $f(x)=- 13 x^{8} + 9 x^{7} - 13 x^{6} + 3$ and interval $[a,b] = [-7, 14]$ to test the code.\n",
    "- Increase the number of subintervals in order to obtain a noticeable difference in the timings.\n",
    "\n",
    "In your handin, include the rewritten code along with the timing measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad578ce-edd2-47f2-a955-2976bf607946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def create_mesh(a, b, n):\n",
    "    return [a+i*(b-a)/n for i in range(n)]\n",
    "def integrate(f, a, b, n):\n",
    "    sum_of_rectangles = 0\n",
    "    left_endpoints = create_mesh(a,b,n)\n",
    "    mesh_width = (b-a)/n\n",
    "    for left_endpoint in left_endpoints:\n",
    "        midpoint = left_endpoint + mesh_width/2\n",
    "        height = f(midpoint)\n",
    "        sum_of_rectangles += height * mesh_width\n",
    "    return sum_of_rectangles\n",
    "def integrate_vectorized(f, a, b, n):\n",
    "    x = np.linspace(a, b, n+1)\n",
    "    fx = f(x)\n",
    "    return np.sum(fx) * (b-a)/n\n",
    "def f(x):\n",
    "    return -13*x**8 + 9*x**7 - 13*x**6 + 3\n",
    "\n",
    "start = time.time()\n",
    "myresult = integrate_vectorized(f, -7, 14, 100000000)\n",
    "end = time.time()\n",
    "print(myresult)\n",
    "print(\"Vectorized version took:\", end - start, \"seconds\")\n",
    "\n",
    "start = time.time()\n",
    "myresult = integrate(f,-7,14,100000000)\n",
    "end = time.time()\n",
    "print(\"Original version took:\", end - start, \"seconds\")\n",
    "\n",
    "# Takes a looooooong time because of the loops\n",
    "# Could include multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0670cdbf-167d-45b5-b2b3-24e1bc8ae4e6",
   "metadata": {},
   "source": [
    "## Problem 4. Numpy arrays\n",
    "\n",
    "- The folder <b>/home/AB0410/data_analytics/private/exrc_01/data</b><br/>\n",
    "  contains a csv file (<b>prob4_AB0410.csv</b>) with some weather data.\n",
    "- a) Use [numpy.genfromtxt](https://numpy.org/doc/stable/reference/generated/numpy.genfromtxt.html) to read the file into a 2-dimensional numpy array.<br/>\n",
    "  Use dtype=str in order to not lose the headers.\n",
    "- b) Use Boolean masking to drop the rows that contain <b>nan</b> entries.\n",
    "- c) Convert the time entries (standard timestamp) into a human-readable format of your choice.\n",
    "- d) Add a new row that contains the averages of the columns, except <b>nan</b> for the time column.\n",
    "\n",
    "In your handin, include the code that does a) - d) above (no saved data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54c404b-f714-45fe-b2f0-b05fdff0ff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from getpass import getuser\n",
    "import csv\n",
    "\n",
    "user = getuser().upper()\n",
    "csv_location = f'/home/{user}/data_analytics/private/exrc_01/data/prob4_AB0410.csv'\n",
    "\n",
    "data = pd.read_csv(csv_location)\n",
    "data = data.dropna()\n",
    "\n",
    "time_col = data['time']\n",
    "time_col = [datetime.fromtimestamp(time) for time in time_col]\n",
    "data['time'] = time_col\n",
    "\n",
    "averages = data.mean(axis=0)\n",
    "averages['time'] = 'nan'\n",
    "data = pd.concat([data, averages.to_frame().T], ignore_index=True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bf511d-2bff-4d3b-8cd3-2231732df527",
   "metadata": {},
   "source": [
    "## Problem 5. Data download\n",
    "- Start by exploring / running the code in <b>data_analytics/lib/statfi.py</b>\n",
    "- Choose a topic that interests you. Then download a few megabytes of data of that topic.\n",
    "- Save your data in one or several json files.\n",
    "\n",
    "In your handin, include the code that you used (no saved data).\n",
    "Also, tell a few words about your experiences. What problems, if any, did you encounter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040781a7-5580-4b3f-9c92-b366eaf824a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cc0e70b-1a6e-40f7-aba7-d12ae5968d8a",
   "metadata": {},
   "source": [
    "## Handin your final answers by running the code cell below.\n",
    "- It lists the notebooks in the same directory as the current one, and asks you to choose the one you want to hand in. (It seems that in JupyterHub one cannot refer to the current file, only to the directory of the current file.)\n",
    "- Save your latest changes first, and please remove anything that may identify you to your anonymous reviewer.\n",
    "- More information about the anonymous reviewing process will appear later.\n",
    "- You may run the code cell as many times as you wish.\n",
    "- Your permission to write the handin file ends at the deadline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e138532-a8ef-4ad6-9538-30756d495dcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/varpha/data_analytics/lib')\n",
    "from handin import handin_exrc_01\n",
    "handin_exrc_01()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
